{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaab578f",
   "metadata": {},
   "source": [
    "---\n",
    "# 將以下4個模型的預測結果做ensembling\n",
    "1. satrn\n",
    "2. sar\n",
    "3. robust scanner\n",
    "4. NRTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8648f",
   "metadata": {},
   "source": [
    "## 讀取4個模型預測出的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('./mmocr/sub_test_satrn_score.csv')\n",
    "df0.score = df0.score.apply(literal_eval)\n",
    "df0['text'] = df0['text'].astype(str)\n",
    "df1 = pd.read_csv('./mmocr/sub_test_sar_score.csv')\n",
    "df1.score = df1.score.apply(literal_eval)\n",
    "df1['text'] = df1['text'].astype(str)\n",
    "df1.columns = [f'{f}_1' for f in df1.columns]\n",
    "df2 = pd.read_csv('./mmocr/sub_test_robustscanner_score.csv')\n",
    "df2.score = df2.score.apply(literal_eval)\n",
    "df2['text'] = df2['text'].astype(str)\n",
    "df2.columns = [f'{f}_2' for f in df2.columns]\n",
    "df3 = pd.read_csv('./mmocr/sub_test_nrtr_score.csv')\n",
    "df3.score = df3.score.apply(literal_eval)\n",
    "df3['text'] = df3['text'].astype(str)\n",
    "df3.columns = [f'{f}_3' for f in df3.columns]\n",
    "\n",
    "mdf = pd.concat([df0, df1, df2, df3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b8925",
   "metadata": {},
   "source": [
    "## 取出4個模型預測不完全一樣的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c73a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "for idx in mdf.index:\n",
    "    if mdf.loc[idx, 'text'] == mdf.loc[idx, 'text_1'] == mdf.loc[idx, 'text_2'] == mdf.loc[idx, 'text_3']:\n",
    "        pass\n",
    "    else:\n",
    "        diff.append(idx)\n",
    "        \n",
    "diff = mdf.loc[diff, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb08a05",
   "metadata": {},
   "source": [
    "## 進行ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx in diff.index:\n",
    "    if len(diff.loc[idx, 'text']) == len(diff.loc[idx, 'text_1']) == len(diff.loc[idx, 'text_2']) == len(diff.loc[idx, 'text_3']):\n",
    "        # same length, merge by char\n",
    "        cur = []\n",
    "        text_len = len(diff.loc[idx, 'text'])\n",
    "        s = diff.loc[idx, 'text']\n",
    "        s1 = diff.loc[idx, 'text_1']\n",
    "        s2 = diff.loc[idx, 'text_2']\n",
    "        s3 = diff.loc[idx, 'text_3']\n",
    "        score = diff.loc[idx, 'score']\n",
    "        score1 = diff.loc[idx, 'score_1']\n",
    "        score2 = diff.loc[idx, 'score_2']\n",
    "        score3 = diff.loc[idx, 'score_3']\n",
    "        for i in range(text_len):\n",
    "            scores = np.array([score[i], score1[i], score2[i], score3[i]])\n",
    "            cur_texts = [s[i], s1[i], s2[i], s3[i]]\n",
    "            max_score_idx = scores.argmax()\n",
    "            cur.append(cur_texts[max_score_idx])\n",
    "                \n",
    "        cur = ''.join(cur)\n",
    "    else:            \n",
    "        candidate_scores = []\n",
    "        candidate_text = []\n",
    "        if len(diff.loc[idx, 'text']) >= 8:\n",
    "            candidate_scores.append('min_score')\n",
    "            candidate_text.append('text')\n",
    "        if len(diff.loc[idx, 'text_1']) >= 8:\n",
    "            candidate_scores.append('min_score_1')\n",
    "            candidate_text.append('text_1')\n",
    "        if len(diff.loc[idx, 'text_2']) >= 8:\n",
    "            candidate_scores.append('min_score_2')\n",
    "            candidate_text.append('text_2')\n",
    "        if len(diff.loc[idx, 'text_3']) >= 8:\n",
    "            candidate_scores.append('min_score_3')\n",
    "            candidate_text.append('text_3')\n",
    "            \n",
    "        # different length, Select the most confidence sentence\n",
    "        most_confidence_idx = diff.loc[idx, candidate_scores].values.argmax()\n",
    "        cur = diff.loc[idx, candidate_text].to_list()[most_confidence_idx]\n",
    "    \n",
    "    res.append(cur)\n",
    "\n",
    "diff['result'] = res\n",
    "mdf.loc[diff.index, ['text']] = diff['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7379aa",
   "metadata": {},
   "source": [
    "## 輸出包含預測信心值的預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce158ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the ensemble result with min_score\n",
    "ensemble_score_df = mdf.loc[:, [\"id\", \"text\"]]\n",
    "ensemble_score_df['min_score'] = mdf.loc[:, [\"min_score\", \"min_score_1\", \"min_score_2\", \"min_score_3\"]].max(axis=1)\n",
    "ensemble_score_df.to_csv(\"ensemble_4models_private_score_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cdb344",
   "metadata": {},
   "source": [
    "## 輸出上傳使用的預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9fbd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the ensemble result for submission\n",
    "output_filename = 'ensemble_4models_private_v2.csv'\n",
    "res = [['id', 'text']]\n",
    "filenames = mdf['id'].to_list()\n",
    "results = mdf['text'].to_list()\n",
    "for f, r in zip(filenames, results):\n",
    "    print(r)\n",
    "    res.append([os.path.splitext(f)[0], r])\n",
    "\n",
    "res = [','.join(r) for r in res]\n",
    "sub_text = '\\r\\n'.join(res)\n",
    "sub_text.rstrip()\n",
    "with open(output_filename, 'w') as f:\n",
    "    f.write(sub_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
